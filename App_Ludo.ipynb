{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9921e8-3662-4790-a7a0-d7ee20215366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\LD259969\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LD259969\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LD259969\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected displays: 2\n",
      "Screen width in pixels : 1920\n",
      "Screen height in pixels : 1080\n",
      "Width scale factor in pixels : 1.0\n",
      "Height scale factor in pixels : 1.0\n",
      "Width scale factor in mm : 1.019271948608137\n",
      "Height scale factor in mm : 1.0\n",
      "Width in pixels of root window is 901 and height in pixels is 699\n"
     ]
    }
   ],
   "source": [
    "from BiblioMeter_GUI.Page_Classes import App_Test\n",
    "\n",
    "app = App_Test()\n",
    "app.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6569a55b-f318-4d92-a0a7-2aa429db0d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[2015, 2016, 2018] != [2015, 2019, 2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1229f46-22ae-4633-8ddb-2afbea6f3b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2014', '2015', '2016', '2017', '2018']\n",
      "['2018', '2017', '2016', '2015', '2014']\n"
     ]
    }
   ],
   "source": [
    "corpus_year = 2018\n",
    "go_back_years = 5\n",
    "\n",
    "today_year = int(2022)\n",
    "start_year = int(corpus_year)\n",
    "time_line_history = int(go_back_years)\n",
    "years = [str(i) for i in range(start_year - time_line_history + 1, start_year + 1)]\n",
    "print(years)\n",
    "years = years[::-1]\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f6e394a-9b25-43a6-870e-3667e1671eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2013, 2014, 2015, 2016, 2017'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join([str(i) for i in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30c013be-5e13-464f-abd0-9699acfcd070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _annee_croisement(corpus_year):\n",
    "    \n",
    "    import pandas\n",
    "    \n",
    "    in_path = r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\Listing RH\\All_effectifs.xlsx\"\n",
    "    df = pandas.read_excel(in_path, sheet_name = None)\n",
    "    \n",
    "    annees_dispo = {', '.join(list(df.keys()))}\n",
    "    \n",
    "    goback = 5\n",
    "    annees_a_verifier = [corpus_year - goback + i for i in range(goback)]\n",
    "    annees_verifiees = list()\n",
    "    \n",
    "    for i in annees_a_verifier:\n",
    "        if i in annees_dispo:\n",
    "            annees_verifiees = annees_verifiees.append(i)\n",
    "            \n",
    "    print(annees_verifiees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f533eb15-209c-4fba-b324-cfbb527e985c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "corpus_year = 2013\n",
    "annees_dispo = [int(x) for x in list(df.keys())]\n",
    "\n",
    "goback = 5\n",
    "annees_a_verifier = [corpus_year - goback + i for i in range(goback)]\n",
    "annees_verifiees = list()\n",
    "\n",
    "for i in annees_a_verifier:\n",
    "    if i in annees_dispo:\n",
    "        annees_verifiees.append(i)\n",
    "\n",
    "if len(annees_verifiees) > 0:\n",
    "    print(1)\n",
    "else:\n",
    "    print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c30ec1e-bf3f-435c-b40a-e062b776be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sauvegarde_des_fichiers_importants(bibliometer_path, Chemin_des_fichiers_importants):\n",
    "    \n",
    "    import os\n",
    "    import shutil\n",
    "    from pathlib import Path\n",
    "    from BiblioMeter_GUI.Globals_GUI import STOCKAGE_ARBORESCENCE\n",
    "    \n",
    "    for fichier in Chemin_des_fichiers_importants:\n",
    "        filePath = shutil.copy(fichier, bibliometer_path / Path(STOCKAGE_ARBORESCENCE['general'][8]) / Path (os.path.basename(fichier)))\n",
    "    \n",
    "    print(\"Fichier sauvegardé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c7ac00ba-c5d4-4a3b-ba2a-d0350b94dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\BDD multi annuelle\\2022-11-07 0919 Concaténation par LD259969 2018 2019 2020 2022.xlsx\"\n",
    "\n",
    "def ISSN_manquant(bibliometer_path, in_path):\n",
    "    \n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    # Standard library imports\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Local library imports\n",
    "    from BiblioMeter_FUNCTS.BiblioMeterGlobalsVariables import COL_NAMES_BONUS\n",
    "    from BiblioMeter_GUI.Globals_GUI import STOCKAGE_ARBORESCENCE\n",
    "    \n",
    "    # 3rd party library imports\n",
    "    import pandas as pd \n",
    "    \n",
    "    # useful alias\n",
    "    alias_IF_annee_publi = COL_NAMES_BONUS['IF année publi']\n",
    "    \n",
    "    ISSN_Liste = list()\n",
    "    out_path = bibliometer_path / Path(STOCKAGE_ARBORESCENCE['general'][7])\n",
    "\n",
    "    df = pd.read_excel(in_path)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if df[alias_IF_annee_publi][i] == 'unknow' or df[alias_IF_annee_publi][i] == 'Not available':\n",
    "            ISSN_Liste.append([df['ISSN'][i], df['Year'][i]])\n",
    "    \n",
    "    df = pd.DataFrame(ISSN_Liste, columns = ['ISSN', 'Year'])\n",
    "    df.drop_duplicates(inplace = True)\n",
    "    \n",
    "    df.to_excel(out_path / Path('ISSN_manquants.xlsx'))\n",
    "    \n",
    "    return print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "54bcdea8-7634-4cf4-8c6d-4082dd7286c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "L = ISSN_manquant(r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\", in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4589c60b-bc6b-4f93-9c70-88e3d5d135ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISSN</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2058-8585</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2073-4360</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0163-1918</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2191-3358</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0888-5885</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1473-8716</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2491-9292</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0360-1323</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2212-9820</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ISSN  Year\n",
       "0      unknown  2018\n",
       "4    2058-8585  2018\n",
       "6    2073-4360  2018\n",
       "7    0163-1918  2018\n",
       "11   2191-3358  2018\n",
       "..         ...   ...\n",
       "372  0888-5885  2022\n",
       "373  1473-8716  2022\n",
       "374  2491-9292  2022\n",
       "375  0360-1323  2022\n",
       "381  2212-9820  2022\n",
       "\n",
       "[171 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a928d5fa-1bc2-4496-9733-c1408affddf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not available'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['IF de l\\'année de publication'][700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bb278a2-a597-4df3-8a67-0eca1175dece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['IF de l\\'année de publication'][0] == 'unknow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe11849b-f02c-4347-9d99-220fb30ae9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unknown'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ISSN'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc537537-ccd7-46d5-8d05-c223a83297fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "\n",
    "ws = Tk()\n",
    "ws.title('Python Guides')\n",
    "ws.geometry('300x200')\n",
    "ws.config(bg='#5FB691')\n",
    "\n",
    "def msg1():\n",
    "    messagebox.askretrycancel('retry', 'Failed! want to try again?')\n",
    "\n",
    "Button(ws, text='Click Me', command=msg1).pack(pady=50)\n",
    "\n",
    "ws.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2879ada2-703f-413e-8aa8-92a668cc132c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Début du brouillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a923e-442a-4ce7-8215-2b1753652986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "\n",
    "fenetre = Tk()\n",
    "fenetre.geometry('400x400')\n",
    "fenetre.title('Luludodo')\n",
    "\n",
    "#salut = ImageTk.PhotoImage(Image.open(r'C:\\Users\\LD259969\\Pictures\\LisAxel.png'))\n",
    "#label = Label(image = salut)\n",
    "#label.pack()\n",
    "\n",
    "button_quit = Button(self, text = \"Exit Program\", command = self.destroy)\n",
    "button_quit.pack()\n",
    "\n",
    "fenetre.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c2fa4-d429-4c4e-966e-c96fcecabb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\2018\\2 - OTP\\fichier_ajout_OTP_DTNM.xlsx\"\n",
    "\n",
    "dirname1 = os.path.basename(path)\n",
    "print(dirname1)\n",
    "dirname2 = os.path.split(path)\n",
    "print(dirname2)\n",
    "\n",
    "from pathlib import Path\n",
    "p = Path(path)\n",
    "print(p.parts[0] / Path(\"...\") / ('/'.join(p.parts[-3:])))\n",
    "os.startfile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f86433-7283-42de-9b64-eb33cbfb49fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.kill(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0719b1-15ae-423b-8979-56a5a24c3019",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\n",
    "a = a + \" afaf\"\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0375a-7d15-4c1c-95ef-b9f907bb1eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = ['109_2018', '122_2018', '136_2018', '147_2018', '148_2018', '170_2018', '177_2018', '194_2018', '195_2018', '1_2018', '211_2018', '252_2018', '263_2018', '264_2018', '267_2018', '270_2018', '273_2018', '275_2018', '282_2018', '287_2018', '288_2018', '289_2018', '291_2018', '299_2018', '306_2018', '313_2018', '314_2018', '319_2018', '324_2018', '326_2018', '329_2018', '330_2018', '336_2018', '338_2018', '339_2018', '342_2018', '345_2018', '346_2018', '352_2018', '353_2018', '355_2018', '359_2018', '360_2018', '361_2018', '365_2018', '373_2018', '374_2018', '383_2018', '392_2018', '41_2018', '43_2018', '46_2018', '56_2018', '78_2018', '90_2018']\n",
    "\n",
    "def _le_reste(num, la_list):\n",
    "    return la_list.index(num)%2 == 0\n",
    "\n",
    "_le_reste('122_2018', hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb1ebc0-c129-498e-b1ab-7277f5950b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"S:\\130-LITEN\\130.1-Directin\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\2018\\2 - OTP\\fichier_ajout_OTP_DTNM.xlsx\"\n",
    "\n",
    "import pandas as pd\n",
    "from BiblioMeter_FUNCTS.BiblioMeterFonctions import mise_en_page\n",
    "\n",
    "df = pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e3a00-f538-4359-9e32-5413c66c8ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb, ws = mise_en_page(df)\n",
    "ws.title = 'OTP DTNM'\n",
    "wb.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afc15ad-a92b-45f9-90e3-b02c6cafac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9469ef0a-689c-412d-a208-9f96f3f8dcd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AJOUTER AUTOMATIQUEMENT CETTE FONCTION A LA PROCEDURE DONE\n",
    "\n",
    "import pandas as pd\n",
    "from BiblioMeter_FUNCTS.BiblioMeterFonctions import add_authors_name_list\n",
    "\n",
    "in_path = r'S:/130-LITEN/130.1-Direction/130.1.2-Direction Scientifique/130.1.2.1-Dossiers en cours/111- Ludovic Desmeuzes/BiblioMeter_Files/2022/BDD multi mensuelle/submit.xlsx'\n",
    "out_path = r'S:/130-LITEN/130.1-Direction/130.1.2-Direction Scientifique/130.1.2.1-Dossiers en cours/111- Ludovic Desmeuzes/BiblioMeter_Files/2022/BDD multi mensuelle/submit.xlsx'\n",
    "\n",
    "add_authors_name_list(in_path, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c4599-fd2b-41c5-8469-dc96de3b6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "in_path = r'S:/130-LITEN/130.1-Direction/130.1.2-Direction Scientifique/130.1.2.1-Dossiers en cours/111- Ludovic Desmeuzes/BiblioMeter_Files/2022/BDD multi mensuelle/submit.xlsx'\n",
    "out_path = r'S:/130-LITEN/130.1-Direction/130.1.2-Direction Scientifique/130.1.2.1-Dossiers en cours/111- Ludovic Desmeuzes/BiblioMeter_Files/2022/BDD multi mensuelle/cleaned_submit.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba2b1b8-5cd8-4b4d-8840-43c7a800afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BiblioMeter_FUNCTS import clean_reorder_rename_submit\n",
    "clean_reorder_rename_submit(in_path, out_path)\n",
    "# A FINIR APRES IMPACT FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b109ab-e304-4b08-8693-62d305beac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes pour écrire dans un document texte\n",
    "path = r'S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\111- Ludovic Desmeuzes\\BiblioMeter_Files\\Listing RH\\MAJ.txt'\n",
    "f = open(path,'r')\n",
    "print(f.readline())\n",
    "f.close()\n",
    "\n",
    "f = open(path,'w')\n",
    "nouvelle_date = f'{date.today().month}/{date.today().year}'\n",
    "f.writelines(nouvelle_date)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04d4b92-2837-4d4d-8946-fd6a01d14039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def maj_listing_RH():\n",
    "\n",
    "    def date_compare(list_of_dates, comparator):\n",
    "        '''\n",
    "        Args:\n",
    "            list_of_dates (list of strings): a list of string of dates in format mmyyyy, mm being the number of the month and yyyy being the number of the year.\n",
    "            comparator (string): a date in string format mmyyyy, mm being the number of the month and yyyy being the number of the year.\n",
    "\n",
    "        Returns:\n",
    "            L (list of strings): a list of the dates older than the comparator date.\n",
    "\n",
    "        '''\n",
    "        L = []\n",
    "        for i in list_of_dates:\n",
    "            if i[2:6] > comparator[2:6]:\n",
    "                # Alors ok pas besoin de vérifier\n",
    "                L.append(i)\n",
    "            elif i[2:6] == comparator[2:6]:\n",
    "                if i[0:2] > comparator[0:2]:\n",
    "                    # Okay si le mois est supérieur\n",
    "                    L.append(i)\n",
    "        return L\n",
    "\n",
    "    def concat_df_with_multidf_and_drop_dup(multi_df, df = pd.DataFrame()):\n",
    "        '''\n",
    "        Args:\n",
    "            multi_df (DataFrame):\n",
    "            df (DataFrame):\n",
    "        Returns:\n",
    "            df (DataFrame):\n",
    "        '''\n",
    "        for i in range(len(multi_df)):\n",
    "            clef = list(df_month.keys())[i]\n",
    "            df = df.append(multi_df[clef])\n",
    "        df.drop_duplicates(subset=['Matricule'], keep='first', inplace=True, ignore_index=False)\n",
    "        return df\n",
    "\n",
    "    def different_years(list_of_dates):\n",
    "        '''\n",
    "        Args:\n",
    "            list_of_dates (list of strings): a list of string of dates in format mmyyyy, mm being the number of the month and yyyy being the number of the year.\n",
    "        Returns:\n",
    "            L (list of strings):\n",
    "        '''\n",
    "        L = []\n",
    "        for i in list_of_dates:\n",
    "            L.append(i[2:6])\n",
    "        return list(set(L))\n",
    "\n",
    "    def dates_of_the_given_year(given_year, list_of_dates):\n",
    "        '''\n",
    "        Args:\n",
    "            given_year (string):\n",
    "            list_of_dates (list of strings): a list of string of dates in format mmyyyy, mm being the number of the month and yyyy being the number of the year.\n",
    "        Returns:\n",
    "            L (list of strings):\n",
    "        '''\n",
    "        L = []\n",
    "        for i in list_of_dates:\n",
    "            if i[2:6] == given_year:\n",
    "                L.append(i)\n",
    "        return L\n",
    "\n",
    "    # Mise à jour fichier RH\n",
    "\n",
    "    import pandas as pd \n",
    "    import numpy as np \n",
    "    from openpyxl import load_workbook \n",
    "\n",
    "    path_year = r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\111- Ludovic Desmeuzes\\BiblioMeter_Files\\Listing RH\\All_effectifs.xlsx\" \n",
    "    path_month = r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\111- Ludovic Desmeuzes\\BiblioMeter_Files\\Listing RH\\Effectifs_2010_2022.xlsx\" \n",
    "    path_maj = r'S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\111- Ludovic Desmeuzes\\BiblioMeter_Files\\Listing RH\\MAJ.txt'\n",
    "\n",
    "    # Récupérer la date de la dernière MAJ\n",
    "    f = open(path_maj,'r')\n",
    "    last_maj = f.readline()\n",
    "    f.close()\n",
    "\n",
    "    # Récupérer les pages dont les dates sont antérieures à last_maj\n",
    "    xls = pd.ExcelFile(path_month, engine = 'openpyxl')\n",
    "    sheets = xls.sheet_names\n",
    "    excel_sheets = date_compare(sheets, last_maj)\n",
    "    print(f\"Toutes les pages à maj sont {excel_sheets}\")\n",
    "\n",
    "    # Récupérer les différentes années et boucler dessus\n",
    "    diff_years = different_years(excel_sheets)\n",
    "    print(f\"Les années différentes sur ces pages sont {diff_years}\")\n",
    "\n",
    "    # Ouverture du workbook et writer\n",
    "    book = load_workbook(path_year)\n",
    "    writer = pd.ExcelWriter(path_year, engine = 'openpyxl', mode = 'a', if_sheet_exists = 'replace') \n",
    "    # writer.book = book\n",
    "\n",
    "    for year in diff_years:\n",
    "        # Les dates des pages à rajouter pour l'année en question\n",
    "        month_pages = dates_of_the_given_year(year, excel_sheets)\n",
    "        print(f\"Pour l'année {year}, les mois sont {month_pages}\")\n",
    "\n",
    "        # La multi df à récupérer de l'année en question pour mettre à jour le fichier effectif de l'année\n",
    "        df_month = pd.read_excel(path_month, sheet_name = month_pages)\n",
    "\n",
    "        # Vérifier l'excistence de la page de l'année de path_year, et si elle existe la récupérer, sinon la créer.\n",
    "        try:\n",
    "            print('Test du try')\n",
    "            df_year = pd.read_excel(path_year, sheet_name = year, engine = 'openpyxl')\n",
    "\n",
    "            print(f\"La page existe ! Tout est bon, on peut continuer\")\n",
    "            df_maj = concat_df_with_multidf_and_drop_dup(df_month, df_year)\n",
    "            #book.remove(year)\n",
    "            df_maj.to_excel(writer, sheet_name = year)\n",
    "\n",
    "            print('Fin du try')\n",
    "\n",
    "        except:\n",
    "            print(f\"La page n'existe pas ! Il faut donc la créer lors de l'ajout de la DataFrame\")\n",
    "            df_maj = concat_df_with_multidf_and_drop_dup(df_month)\n",
    "            df_maj.to_excel(writer, sheet_name = year)\n",
    "\n",
    "            print('Fin du except')\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "\n",
    "    print('Terminé, vous pouvez ouvrir le fichier excel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8765f04-aa24-4ec3-a1c4-edc749bf70b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajout_IF(in_path, out_path, IF_path, year):\n",
    "    \n",
    "    ''' \n",
    "\n",
    "    Args:\n",
    "        in_path (path): path (including name of the file if year != None) leading to the working excel file. \n",
    "        out_path (path): path (including name of the file) leading to where the file will be saved after going through its treatment.\n",
    "        IF_path (path): path (including name of the file) leading to the impact factor excel file.\n",
    "        year (int):\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    Notes:\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    print(f\"in_path = {in_path}\")\n",
    "    \n",
    "    # Standard imports\n",
    "    from pathlib import Path\n",
    "\n",
    "    # Local imports\n",
    "    from BiblioMeter_FUNCTS.BiblioMeterGlobalsVariables import COL_NAMES_BONUS\n",
    "    from BiblioAnalysis_Utils.BiblioSpecificGlobals import COL_NAMES\n",
    "    from BiblioMeter_FUNCTS.BiblioMeterGlobalsVariables import FILL_EMPTY_KEY_WORD\n",
    "\n",
    "    # 3rd party imports\n",
    "    import pandas as pd\n",
    "\n",
    "    # Useful alias\n",
    "    ISSN_alias = COL_NAMES['articles'][10]\n",
    "    EISSN_alias = COL_NAMES_BONUS['EISSN']\n",
    "    IF_alias = COL_NAMES_BONUS['If clarivate']\n",
    "    IF_cours_alias = COL_NAMES_BONUS['IF en cours']\n",
    "    IF_publi_alias = COL_NAMES_BONUS['IF année publi']\n",
    "    \n",
    "    df_submit = pd.read_excel(in_path) # Ma DataFrame\n",
    "    \n",
    "    if year == None:\n",
    "        df_IF = pd.read_excel(IF_path, sheet_name = None)\n",
    "        \n",
    "        # using dictionary to convert type of  Year column\n",
    "        convert_dict = {'Year': str}\n",
    "        df_submit = df_submit.astype(convert_dict)\n",
    "\n",
    "        list_annee = list(df_submit['Year'].unique())\n",
    "        try :\n",
    "            list_annee.remove('unknown')\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "        # Maintenant qu'on a les années, on boucle dessus pour appliquer un filtre\n",
    "        df_submit_bis = pd.DataFrame()\n",
    "        for annee in list_annee:\n",
    "            print(annee)\n",
    "            df_inter = df_submit[df_submit['Year'] == annee]\n",
    "            \n",
    "            try:\n",
    "                dict1 = dict(zip(df_IF[str(int(annee) + 1)][ISSN_alias], df_IF[str(int(annee) + 1)][IF_alias]))\n",
    "                \n",
    "                s = df_inter[ISSN_alias] # Je récup la colonne clef de ma DF en Series\n",
    "                \n",
    "                r = s.map(dict1) # Je map la Series avec mon dictionnaire\n",
    "                                \n",
    "                df_inter[Impact_Factor_alias] = r # Je rajoute la colonne à ma DataFrame\n",
    "                \n",
    "                # Appliquer nan --> unknow to df\n",
    "                df_inter[Impact_Factor_alias] = df_inter[Impact_Factor_alias].fillna(FILL_EMPTY_KEY_WORD)\n",
    "\n",
    "                df_submit_bis = df_submit_bis.append(df_inter)\n",
    "                \n",
    "            except KeyError:\n",
    "                dict1 = dict(zip(df_IF[str(annee)][ISSN_alias], df_IF[str(annee)][IF_alias]))\n",
    "                \n",
    "                s = df_inter[ISSN_alias] # Je récup la colonne clef de ma DF en Series\n",
    "                \n",
    "                r = s.map(dict1) # Je map la Series avec mon dictionnaire\n",
    "                \n",
    "                df_inter[Impact_Factor_alias] = r # Je rajoute la colonne à ma DataFrame\n",
    "                \n",
    "                # Appliquer nan --> unknow to df\n",
    "                df_inter[Impact_Factor_alias] = df_inter[Impact_Factor_alias].fillna(FILL_EMPTY_KEY_WORD)\n",
    "\n",
    "                df_submit_bis = df_submit_bis.append(df_inter)\n",
    "            \n",
    "        df_submit_bis.to_excel(out_path, index = False)\n",
    "                \n",
    "    \n",
    "    else: # Mode de fonctionnement par année\n",
    "        # Check if the year + 1 is available\n",
    "        try:\n",
    "            df_IF = pd.read_excel(IF_path, sheet_name = str(year + 1))\n",
    "            # Ca fonctionne, alors on ajoute la colonne IF de l'année en cours\n",
    "            print(f\"Les IF sortis en {year +1} sont utilisés pour créer la colonne f{IF_cours_alias}\")\n",
    "\n",
    "            dict1 = dict(zip(df_IF[ISSN_alias], df_IF[IF_alias])) # Mon dictionnaire construit à partir de mon fichier excel\n",
    "            s = df_submit[ISSN_alias] # Je récup la colonne clef de ma DF en Series\n",
    "            r = s.map(dict1) # Je map la Series avec mon dictionnaire\n",
    "            df_submit[IF_cours_alias] = r # Je rajoute la colonne à ma DataFrame\n",
    "\n",
    "            # Appliquer nan --> unknow to df TO DO\n",
    "            df_submit[IF_cours_alias] = df_submit[IF_cours_alias].fillna(FILL_EMPTY_KEY_WORD)\n",
    "            \n",
    "            # Et on fait pareil avec les IF de l'année de publication\n",
    "            print(f\"Les IF sortis en {year} sont utilisés pour créer la colonne f{IF_publi_alias}\")\n",
    "\n",
    "            dict1 = dict(zip(df_IF[ISSN_alias], df_IF[IF_alias])) # Mon dictionnaire construit à partir de mon fichier excel\n",
    "            s = df_submit[ISSN_alias] # Je récup la colonne clef de ma DF en Series\n",
    "            r = s.map(dict1) # Je map la Series avec mon dictionnaire\n",
    "            df_submit[IF_publi_alias] = r # Je rajoute la colonne à ma DataFrame\n",
    "\n",
    "            # Appliquer nan --> unknow to df\n",
    "            df_submit[IF_publi_alias] = df_submit[IF_publi_alias].fillna(FILL_EMPTY_KEY_WORD)\n",
    "            \n",
    "            df_submit.to_excel(out_path, index = False)\n",
    "                \n",
    "        except ValueError:\n",
    "            # Check if the year is available, if not, terminate function\n",
    "            try:\n",
    "                df_IF = pd.read_excel(IF_path, sheet_name = str(year))\n",
    "                print(f\"Les IF sortis en {year} sont utilisés\")\n",
    "                \n",
    "                dict1 = dict(zip(df_IF[ISSN_alias], df_IF[IF_alias])) # Mon dictionnaire construit à partir de mon fichier excel\n",
    "                \n",
    "                s = df_submit[ISSN_alias] # Je récup la colonne clef de ma DF en Series\n",
    "                \n",
    "                r = s.map(dict1) # Je map la Series avec mon dictionnaire\n",
    "                \n",
    "                df_submit[Impact_Factor_alias] = r # Je rajoute la colonne à ma DataFrame\n",
    "                \n",
    "                # Appliquer nan --> unknow to df\n",
    "                df_submit[Impact_Factor_alias] = df_submit[Impact_Factor_alias].fillna(FILL_EMPTY_KEY_WORD)\n",
    "\n",
    "                df_submit.to_excel(out_path, index = False)\n",
    "                \n",
    "            except ValueError:\n",
    "                print('Mettre à jour le fichier Impact Factor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a196e872-2c71-4a28-878e-d76793a675ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "in_path = Path(r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\BDD multi annuelle\") / Path(os.listdir(r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\BDD multi annuelle\")[-2])\n",
    "IF_path = Path(r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\Impact Factor\\IF all years.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b7cc0-a176-433b-9f07-bc81d1300fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07e8b7-f0f9-45a8-9fcd-3b223c18297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BiblioMeter_FUNCTS.BiblioMeterFonctions import ajout_IF\n",
    "ajout_IF(in_path, in_path, IF_path, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f58484-7a96-4e94-af6b-be152800f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_IF = pd.read_excel(IF_path, sheet_name = '2023')\n",
    "except ValueError:\n",
    "    try:\n",
    "        df_IF = pd.read_excel(IF_path, sheet_name = '2022')\n",
    "        print('Tout a fonctionné')\n",
    "    except ValueError:\n",
    "        print('Mettre à jour le fichier Impact Factor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c0656b-1ea1-40b9-aeb9-cd08d5ed0744",
   "metadata": {},
   "outputs": [],
   "source": [
    "'2023' in df_IF.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde345f-02b3-47f5-be60-ae042e07774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31d419d-5e3e-4a89-b502-ccc517c76b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9d439f-5148-4a43-a082-2100a1171759",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = Path(r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\BDD multi annuelle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b04496-65d3-4013-8005-501dde8b444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a5ae5a-fd91-48b1-adca-0ec6db303af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_IF.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea649a-8ac1-4a19-b763-76b3eee44e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "IF_path = Path(r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\Impact Factor\\IF all years.xlsx\")\n",
    "\n",
    "df_IF_2021 = pd.read_excel(IF_path, sheet_name = \"2021\")\n",
    "df_IF_2020 = pd.read_excel(IF_path, sheet_name = \"2020\")\n",
    "\n",
    "dict1 = dict(zip(df_IF_2021['Journal Majuscule'], df_IF_2021['ISSN'])) # Création dictionnaire avec les noms des journaux de la fiche 2020 et des ISSN dispo de l’année 2022\n",
    "\n",
    "s = df_IF_2020['Journal Majuscule'] # Mettre en type série la colonne avec les noms des journaux (car le map ne fonctionne qu’avec les séries)\n",
    "\n",
    "r = s.map(dict1) # Effectuer le map avec la série et le dictionnaire\n",
    "\n",
    "df_IF_2020['ISSN'] = r # Rajouter le map (r) à la DF\n",
    "\n",
    "df_IF_2020.to_excel(IF_path, sheet_name = \"2020 new\", header = True) # Envoyer sur le fichier excel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78959713-1f4f-4a44-aafd-0a7703674586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rename_pub_id(old, annee):\n",
    "    return f\"{old}_{annee}\"\n",
    "\n",
    "df['Pub_id'] = df['Pub_id'].apply(lambda x: _rename_pub_id(x, '2014'))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37298395-ca03-41cf-a615-dec36b97f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_column_names(df, dictionnary = None):\n",
    "    '''\n",
    "    The function `rename_column_names` changes names of columns of the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame()):\n",
    "        dictionnary (dict):\n",
    "    \n",
    "    Returns:\n",
    "        df (pandas.DataFrame()):\n",
    "    \n",
    "    Notes:\n",
    "        Uses COL_NAMES_FINALE from BiblioMeter_FUNCTS.BiblioMeterGlobalsVariables\n",
    "    '''\n",
    "    \n",
    "    # 3rd Library imports\n",
    "    import pandas as pd\n",
    "    \n",
    "    if dictionnary == None:\n",
    "        # Local library imports\n",
    "        from BiblioMeter_FUNCTS.BiblioMeterGlobalsVariables import COL_NAMES_FINALE\n",
    "        dictionnary = COL_NAMES_FINALE\n",
    "        \n",
    "    df.rename(columns = dictionnary, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9937b25c-d76f-44c0-a170-f4dd3f1d8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "out_path = r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\2018\\1 - Consolidation Homonymes\\Fichier Consolidation 2018.xlsx\"\n",
    "in_path = r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\2018\\0 - BDD multi mensuelle\\submit.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb3b1d-8552-413f-b132-9f72ba2f96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.read_excel(in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dbe543-d214-43e9-854c-844f9332508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit['Pub_id'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210ef4e-689e-4663-9aa3-62e5eb56a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BiblioMeter_FUNCTS.BiblioMeterFonctions import _liste_de_validation\n",
    "from BiblioMeter_FUNCTS.BiblioMeterFonctions import _you_got_OTPed\n",
    "\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.worksheet.datavalidation import DataValidation\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.utils.cell import get_column_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4506ad65-24bd-4613-9f8f-b7dd5f73b683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mise_en_page(df_submit):\n",
    "        \n",
    "    # 3rd party import\n",
    "    import pandas as pd\n",
    "    from openpyxl import Workbook\n",
    "    from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "    from openpyxl.utils import get_column_letter\n",
    "    from openpyxl.styles import Font, PatternFill, Border, Side, Alignment\n",
    "    from openpyxl.styles.colors import Color\n",
    "    \n",
    "    # Local library import\n",
    "    from BiblioMeter_FUNCTS.BiblioMeterGlobalsVariables import COL_SIZES\n",
    "    \n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = 'Consolidation Homonymes'\n",
    "    \n",
    "    red_ft = PatternFill(fgColor = '00FF0000', fill_type = \"solid\")\n",
    "    blue_ft = PatternFill(fgColor = '0000FFFF', fill_type = \"solid\")\n",
    "    bd = Side(style='medium', color=\"000000\")\n",
    "    active_color = 'red'\n",
    "    \n",
    "    pub_id_unique_list = list(df_submit['Pub_id'].unique())\n",
    "    columns_list = list(df_submit.columns)\n",
    "    \n",
    "    def _le_reste(num, la_list):\n",
    "        return la_list.index(num)%2 == 0\n",
    "        \n",
    "    for indice, r in enumerate(dataframe_to_rows(df_submit, index=False, header=True)):\n",
    "        ws.append(r)        \n",
    "        last_row = ws[ws.max_row]\n",
    "        if indice >= 1:\n",
    "            if _le_reste(df_submit['Pub_id'][indice-1], pub_id_unique_list):\n",
    "                cell = last_row[0]\n",
    "                cell.fill = red_ft\n",
    "                if active_color != 'red':\n",
    "                    for cell_bis in last_row:\n",
    "                        cell_bis.border = Border(top=bd)\n",
    "                        active_color = 'red'\n",
    "            else:\n",
    "                cell = last_row[0]\n",
    "                cell.fill = blue_ft\n",
    "                if active_color != 'blue':\n",
    "                    for cell_bis in last_row:\n",
    "                        cell_bis.border = Border(top=bd)\n",
    "                        active_color = 'blue'\n",
    "\n",
    "    for cell in ws['A'] + ws[1]:\n",
    "        cell.font = Font(bold=True)\n",
    "        cell.border = Border(left=bd, top=bd, right=bd, bottom=bd)\n",
    "        cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "        \n",
    "    for i, col in enumerate(columns_list):\n",
    "        if i >= 1:\n",
    "            try:\n",
    "                ws.column_dimensions[get_column_letter(i+1)].width = COL_SIZES[col]\n",
    "            except:\n",
    "                ws.column_dimensions[get_column_letter(i+1)].width = 15\n",
    "        \n",
    "    ws.row_dimensions[1].height = 30\n",
    "    \n",
    "    wb.save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7513ec-ebf2-4edb-9070-edad7420f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import Tk\n",
    "from tkinter import ttk\n",
    "from screeninfo import get_monitors\n",
    "get_monitors()\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "# Get screens\n",
    "Displays = get_displays()\n",
    "\n",
    "displays_nb = len(Displays)\n",
    "GUI_DISP = [i for i in range(displays_nb) if Displays[i]['is_primary']][0]\n",
    "ppi = Displays[GUI_DISP][\"ppi\"]\n",
    "\n",
    "root, scale_factor, win_width, win_height = general_properties(root)\n",
    "\n",
    "print(win_width, win_height)\n",
    "\n",
    "# Set the fontsize based on scale_factor,\n",
    "# if the fontsize is less than minimum_size\n",
    "# it is set to the minimum size\n",
    "def _font_size(size, scale_factor):\n",
    "    \n",
    "    fontsize = int(size * scale_factor)\n",
    "    \n",
    "    minimum_size = 8\n",
    "    if fontsize < minimum_size:\n",
    "        fontsize = minimum_size\n",
    "        \n",
    "    return fontsize\n",
    "\n",
    "### Choose which year you want to be working with #############################################################################################################\n",
    "years_list = [2021, 2022]\n",
    "years_var = tk.StringVar(root)\n",
    "years_var.set(years_list[0])\n",
    "    \n",
    "# Création de l'option button des années\n",
    "OptionButton_years = tk.OptionMenu(root, years_var, *years_list)\n",
    "\n",
    "button1 = tk.Button(root, text=\"Section 1\", font = (\"Helvetica\", _font_size(35, scale_factor)))\n",
    "button1.place(x = win_width/2, y = win_height/4*1, anchor = 'center')\n",
    "\n",
    "button2 = tk.Button(root, text=\"Section 2\", font = (\"Helvetica\", _font_size(15, scale_factor)))\n",
    "button2.place(x = win_width/2, y = win_height/4*3, anchor = 'center')\n",
    "\n",
    "entry1 = tk.Entry(root, width = 41)\n",
    "entry1.place(x = win_width/2, y =  win_height/4*2, anchor = 'center')\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12d1f84-8455-4b5b-8f6e-1ad40c818e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_properties(self):\n",
    "\n",
    "    # Base size\n",
    "    normal_width = 1920\n",
    "    normal_height = 1080\n",
    "\n",
    "    # Get screen size\n",
    "    screen_width = self.winfo_screenwidth()\n",
    "    print(screen_width)\n",
    "    screen_height = self.winfo_screenheight()\n",
    "    print(screen_height)\n",
    "\n",
    "    # Get percentage of screen size from Base size\n",
    "    percentage_width = screen_width / (normal_width / 100)\n",
    "    percentage_height = screen_height / (normal_height / 100)\n",
    "\n",
    "    # Make a scaling factor, this is bases on average percentage from\n",
    "    # width and height.\n",
    "    scale_factor = ((percentage_width + percentage_height) / 2) / 100\n",
    "    \n",
    "    # Set window size depending on scale factor\n",
    "    win_width = int(screen_width*0.47*scale_factor)\n",
    "    win_height = int(screen_height*0.65*scale_factor)\n",
    "\n",
    "    # Set window size depending on scalre factor\n",
    "    self.geometry(f\"{win_width}x{win_height}\")\n",
    "    self.resizable(False, False)\n",
    "    \n",
    "    # Set title window\n",
    "    self.title('BiblioMeter')\n",
    "    \n",
    "    return self, scale_factor, win_width, win_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95679e44-9b6f-4f96-8621-e0adf8dfcf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "173 mm = 699 px largeur\n",
    "233 mm = 901 px hauteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae153e0-dbeb-4673-84be-c2a0e660d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mm_to_px(size_mm, ppi ,fact = 1.0):\n",
    "    '''The `_mm_to_px' function converts a value in mm to a value in pixels\n",
    "    using the ppi of the used display and a factor fact.\n",
    "    \n",
    "    Args:\n",
    "        size_mm (float): value in mm to be converted.\n",
    "        ppi ( float): pixels per inch of the display.\n",
    "        fact (float): factor (default= 1).\n",
    "        \n",
    "    Returns:\n",
    "        `(int)`: upper integer value of the conversion to pixels\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # Standard library imports \n",
    "    import math\n",
    "    \n",
    "    # Local imports\n",
    "    from BiblioAnalysis_Utils.BiblioGeneralGlobals import IN_TO_MM\n",
    "\n",
    "    size_px = math.ceil((size_mm * fact / IN_TO_MM) * ppi)\n",
    "    \n",
    "    return size_px\n",
    "\n",
    "def get_displays(in_to_mm = None): \n",
    "    \n",
    "    ''' The function `get_displays` allows to identify the set of displays\n",
    "        available within the user hardware and to get their parameters.\n",
    "        If the width or the height of a display are not available in mm \n",
    "        through the `get_monitors` method (as for Darwin platforms), \n",
    "        the user is asked to specify the displays diagonal size to compute them.\n",
    "        \n",
    "    Returns:\n",
    "        `list`: list of dicts with one dict per detected display,\n",
    "                each dict is keyed by 8 display parameters.   \n",
    "    '''\n",
    "    # To Do: convert prints and inputs to gui displays and inputs\n",
    "    \n",
    "    # Standard library imports\n",
    "    import math\n",
    "    \n",
    "    # 3rd party imports\n",
    "    from screeninfo import get_monitors\n",
    "    \n",
    "    # Local imports\n",
    "    from BiblioAnalysis_Utils.BiblioGeneralGlobals import IN_TO_MM\n",
    "\n",
    "    if in_to_mm==None: in_to_mm = IN_TO_MM\n",
    "    \n",
    "    displays = [{'x':m.x,'y':m.y,'width':m.width,\n",
    "                 'height':m.height,'width_mm':m.width_mm,\n",
    "                 'height_mm':m.height_mm,'name':m.name,\n",
    "                 'is_primary':m.is_primary} for m in get_monitors()]\n",
    "    \n",
    "\n",
    "    print('Number of detected displays:',len(displays))\n",
    "    \n",
    "    for disp in range(len(displays)):\n",
    "        width_px = displays[disp]['width']\n",
    "        height_px = displays[disp]['height']\n",
    "        diag_px = math.sqrt(int(width_px)**2 + int(height_px)**2)    \n",
    "        width_mm = displays[disp]['width_mm']\n",
    "        height_mm = displays[disp]['height_mm']\n",
    "        if width_mm is None or height_mm is None: \n",
    "            diag_in = float(input('Enter the diagonal size of the screen n°' + str(disp) + ' (inches)'))\n",
    "            width_mm = round(int(width_px) * (diag_in/diag_px) * in_to_mm,1)\n",
    "            height_mm = round(int(height_px) * (diag_in/diag_px) * in_to_mm,1)\n",
    "            displays[disp]['width_mm'] = str(width_mm)\n",
    "            displays[disp]['height_mm'] = str(height_mm)\n",
    "        else:\n",
    "            diag_in = math.sqrt(float(width_mm) ** 2 + float(height_mm) ** 2) / in_to_mm\n",
    "        displays[disp]['ppi'] = round(diag_px/diag_in,2)\n",
    "        \n",
    "    return displays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d3dc71-a0b0-409c-99c4-dee90d24ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from screeninfo import get_monitors\n",
    "get_monitors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c9497-6758-4188-b642-1877e7b22447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BiblioMeter_kernel",
   "language": "python",
   "name": "bibliometer_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
