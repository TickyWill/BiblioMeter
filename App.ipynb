{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9921e8-3662-4790-a7a0-d7ee20215366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\LD259969\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LD259969\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LD259969\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected displays: 2\n"
     ]
    }
   ],
   "source": [
    "from BiblioMeter_GUI.Page_Classes import App_Test\n",
    "\n",
    "app = App_Test()\n",
    "app.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e0a923e-442a-4ce7-8215-2b1753652986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "\n",
    "fenetre = Tk()\n",
    "fenetre.geometry('400x400')\n",
    "fenetre.title('Luludodo')\n",
    "\n",
    "#salut = ImageTk.PhotoImage(Image.open(r'C:\\Users\\LD259969\\Pictures\\LisAxel.png'))\n",
    "#label = Label(image = salut)\n",
    "#label.pack()\n",
    "\n",
    "button_quit = Button(self, text = \"Exit Program\", command = self.destroy)\n",
    "button_quit.pack()\n",
    "\n",
    "fenetre.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "267c2fa4-d429-4c4e-966e-c96fcecabb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fichier_ajout_OTP_DTNM.xlsx\n",
      "('S:\\\\130-LITEN\\\\130.1-Direction\\\\130.1.2-Direction Scientifique\\\\130.1.2.1-Dossiers en cours\\\\110-Alternants\\\\2021-22 Ludovic Desmeuzes\\\\BiblioMeter_Files\\\\2018\\\\2 - OTP', 'fichier_ajout_OTP_DTNM.xlsx')\n",
      "S:\\...\\2018\\2 - OTP\\fichier_ajout_OTP_DTNM.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\2018\\2 - OTP\\fichier_ajout_OTP_DTNM.xlsx\"\n",
    "\n",
    "dirname1 = os.path.basename(path)\n",
    "print(dirname1)\n",
    "dirname2 = os.path.split(path)\n",
    "print(dirname2)\n",
    "\n",
    "from pathlib import Path\n",
    "p = Path(path)\n",
    "print(p.parts[0] / Path(\"...\") / ('/'.join(p.parts[-3:])))\n",
    "os.startfile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8f86433-7283-42de-9b64-eb33cbfb49fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "kill() takes exactly 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_77416\\3802214002.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: kill() takes exactly 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "os.kill(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb0719b1-15ae-423b-8979-56a5a24c3019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' afaf'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"\"\n",
    "a = a + \" afaf\"\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80c0375a-7d15-4c1c-95ef-b9f907bb1eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello = ['109_2018', '122_2018', '136_2018', '147_2018', '148_2018', '170_2018', '177_2018', '194_2018', '195_2018', '1_2018', '211_2018', '252_2018', '263_2018', '264_2018', '267_2018', '270_2018', '273_2018', '275_2018', '282_2018', '287_2018', '288_2018', '289_2018', '291_2018', '299_2018', '306_2018', '313_2018', '314_2018', '319_2018', '324_2018', '326_2018', '329_2018', '330_2018', '336_2018', '338_2018', '339_2018', '342_2018', '345_2018', '346_2018', '352_2018', '353_2018', '355_2018', '359_2018', '360_2018', '361_2018', '365_2018', '373_2018', '374_2018', '383_2018', '392_2018', '41_2018', '43_2018', '46_2018', '56_2018', '78_2018', '90_2018']\n",
    "\n",
    "def _le_reste(num, la_list):\n",
    "    return la_list.index(num)%2 == 0\n",
    "\n",
    "_le_reste('122_2018', hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb1ebc0-c129-498e-b1ab-7277f5950b54",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'S:\\\\130-LITEN\\\\130.1-Directin\\\\130.1.2-Direction Scientifique\\\\130.1.2.1-Dossiers en cours\\\\110-Alternants\\\\2021-22 Ludovic Desmeuzes\\\\BiblioMeter_Files\\\\2018\\\\2 - OTP\\\\fichier_ajout_OTP_DTNM.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_53936\\2182887182.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mBiblioMeter_FUNCTS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBiblioMeterFonctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmise_en_page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\PyVenv\\BiblioMeter\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PyVenv\\BiblioMeter\\venv\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\Documents\\PyVenv\\BiblioMeter\\venv\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1189\u001b[0m                 \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xls\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m                 ext = inspect_excel_format(\n\u001b[0m\u001b[0;32m   1192\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m                 )\n",
      "\u001b[1;32m~\\Documents\\PyVenv\\BiblioMeter\\venv\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1070\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m   1071\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m     ) as handle:\n",
      "\u001b[1;32m~\\Documents\\PyVenv\\BiblioMeter\\venv\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'S:\\\\130-LITEN\\\\130.1-Directin\\\\130.1.2-Direction Scientifique\\\\130.1.2.1-Dossiers en cours\\\\110-Alternants\\\\2021-22 Ludovic Desmeuzes\\\\BiblioMeter_Files\\\\2018\\\\2 - OTP\\\\fichier_ajout_OTP_DTNM.xlsx'"
     ]
    }
   ],
   "source": [
    "path = r\"S:\\130-LITEN\\130.1-Directin\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\2018\\2 - OTP\\fichier_ajout_OTP_DTNM.xlsx\"\n",
    "\n",
    "import pandas as pd\n",
    "from BiblioMeter_FUNCTS.BiblioMeterFonctions import mise_en_page\n",
    "\n",
    "df = pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e3a00-f538-4359-9e32-5413c66c8ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb, ws = mise_en_page(df)\n",
    "ws.title = 'OTP DTNM'\n",
    "wb.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afc15ad-a92b-45f9-90e3-b02c6cafac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path.home()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2879ada2-703f-413e-8aa8-92a668cc132c",
   "metadata": {},
   "source": [
    "# Début du brouillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9469ef0a-689c-412d-a208-9f96f3f8dcd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AJOUTER AUTOMATIQUEMENT CETTE FONCTION A LA PROCEDURE DONE\n",
    "\n",
    "import pandas as pd\n",
    "from BiblioMeter_FUNCTS.BiblioMeterFonctions import add_authors_name_list\n",
    "\n",
    "in_path = r'S:/130-LITEN/130.1-Direction/130.1.2-Direction Scientifique/130.1.2.1-Dossiers en cours/111- Ludovic Desmeuzes/BiblioMeter_Files/2022/BDD multi mensuelle/submit.xlsx'\n",
    "out_path = r'S:/130-LITEN/130.1-Direction/130.1.2-Direction Scientifique/130.1.2.1-Dossiers en cours/111- Ludovic Desmeuzes/BiblioMeter_Files/2022/BDD multi mensuelle/submit.xlsx'\n",
    "\n",
    "add_authors_name_list(in_path, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c4599-fd2b-41c5-8469-dc96de3b6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "in_path = r'S:/130-LITEN/130.1-Direction/130.1.2-Direction Scientifique/130.1.2.1-Dossiers en cours/111- Ludovic Desmeuzes/BiblioMeter_Files/2022/BDD multi mensuelle/submit.xlsx'\n",
    "out_path = r'S:/130-LITEN/130.1-Direction/130.1.2-Direction Scientifique/130.1.2.1-Dossiers en cours/111- Ludovic Desmeuzes/BiblioMeter_Files/2022/BDD multi mensuelle/cleaned_submit.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba2b1b8-5cd8-4b4d-8840-43c7a800afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BiblioMeter_FUNCTS import clean_reorder_rename_submit\n",
    "clean_reorder_rename_submit(in_path, out_path)\n",
    "# A FINIR APRES IMPACT FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b109ab-e304-4b08-8693-62d305beac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes pour écrire dans un document texte\n",
    "path = r'S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\111- Ludovic Desmeuzes\\BiblioMeter_Files\\Listing RH\\MAJ.txt'\n",
    "f = open(path,'r')\n",
    "print(f.readline())\n",
    "f.close()\n",
    "\n",
    "f = open(path,'w')\n",
    "nouvelle_date = f'{date.today().month}/{date.today().year}'\n",
    "f.writelines(nouvelle_date)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04d4b92-2837-4d4d-8946-fd6a01d14039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def maj_listing_RH():\n",
    "\n",
    "    def date_compare(list_of_dates, comparator):\n",
    "        '''\n",
    "        Args:\n",
    "            list_of_dates (list of strings): a list of string of dates in format mmyyyy, mm being the number of the month and yyyy being the number of the year.\n",
    "            comparator (string): a date in string format mmyyyy, mm being the number of the month and yyyy being the number of the year.\n",
    "\n",
    "        Returns:\n",
    "            L (list of strings): a list of the dates older than the comparator date.\n",
    "\n",
    "        '''\n",
    "        L = []\n",
    "        for i in list_of_dates:\n",
    "            if i[2:6] > comparator[2:6]:\n",
    "                # Alors ok pas besoin de vérifier\n",
    "                L.append(i)\n",
    "            elif i[2:6] == comparator[2:6]:\n",
    "                if i[0:2] > comparator[0:2]:\n",
    "                    # Okay si le mois est supérieur\n",
    "                    L.append(i)\n",
    "        return L\n",
    "\n",
    "    def concat_df_with_multidf_and_drop_dup(multi_df, df = pd.DataFrame()):\n",
    "        '''\n",
    "        Args:\n",
    "            multi_df (DataFrame):\n",
    "            df (DataFrame):\n",
    "        Returns:\n",
    "            df (DataFrame):\n",
    "        '''\n",
    "        for i in range(len(multi_df)):\n",
    "            clef = list(df_month.keys())[i]\n",
    "            df = df.append(multi_df[clef])\n",
    "        df.drop_duplicates(subset=['Matricule'], keep='first', inplace=True, ignore_index=False)\n",
    "        return df\n",
    "\n",
    "    def different_years(list_of_dates):\n",
    "        '''\n",
    "        Args:\n",
    "            list_of_dates (list of strings): a list of string of dates in format mmyyyy, mm being the number of the month and yyyy being the number of the year.\n",
    "        Returns:\n",
    "            L (list of strings):\n",
    "        '''\n",
    "        L = []\n",
    "        for i in list_of_dates:\n",
    "            L.append(i[2:6])\n",
    "        return list(set(L))\n",
    "\n",
    "    def dates_of_the_given_year(given_year, list_of_dates):\n",
    "        '''\n",
    "        Args:\n",
    "            given_year (string):\n",
    "            list_of_dates (list of strings): a list of string of dates in format mmyyyy, mm being the number of the month and yyyy being the number of the year.\n",
    "        Returns:\n",
    "            L (list of strings):\n",
    "        '''\n",
    "        L = []\n",
    "        for i in list_of_dates:\n",
    "            if i[2:6] == given_year:\n",
    "                L.append(i)\n",
    "        return L\n",
    "\n",
    "    # Mise à jour fichier RH\n",
    "\n",
    "    import pandas as pd \n",
    "    import numpy as np \n",
    "    from openpyxl import load_workbook \n",
    "\n",
    "    path_year = r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\111- Ludovic Desmeuzes\\BiblioMeter_Files\\Listing RH\\All_effectifs.xlsx\" \n",
    "    path_month = r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\111- Ludovic Desmeuzes\\BiblioMeter_Files\\Listing RH\\Effectifs_2010_2022.xlsx\" \n",
    "    path_maj = r'S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\111- Ludovic Desmeuzes\\BiblioMeter_Files\\Listing RH\\MAJ.txt'\n",
    "\n",
    "    # Récupérer la date de la dernière MAJ\n",
    "    f = open(path_maj,'r')\n",
    "    last_maj = f.readline()\n",
    "    f.close()\n",
    "\n",
    "    # Récupérer les pages dont les dates sont antérieures à last_maj\n",
    "    xls = pd.ExcelFile(path_month, engine = 'openpyxl')\n",
    "    sheets = xls.sheet_names\n",
    "    excel_sheets = date_compare(sheets, last_maj)\n",
    "    print(f\"Toutes les pages à maj sont {excel_sheets}\")\n",
    "\n",
    "    # Récupérer les différentes années et boucler dessus\n",
    "    diff_years = different_years(excel_sheets)\n",
    "    print(f\"Les années différentes sur ces pages sont {diff_years}\")\n",
    "\n",
    "    # Ouverture du workbook et writer\n",
    "    book = load_workbook(path_year)\n",
    "    writer = pd.ExcelWriter(path_year, engine = 'openpyxl', mode = 'a', if_sheet_exists = 'replace') \n",
    "    # writer.book = book\n",
    "\n",
    "    for year in diff_years:\n",
    "        # Les dates des pages à rajouter pour l'année en question\n",
    "        month_pages = dates_of_the_given_year(year, excel_sheets)\n",
    "        print(f\"Pour l'année {year}, les mois sont {month_pages}\")\n",
    "\n",
    "        # La multi df à récupérer de l'année en question pour mettre à jour le fichier effectif de l'année\n",
    "        df_month = pd.read_excel(path_month, sheet_name = month_pages)\n",
    "\n",
    "        # Vérifier l'excistence de la page de l'année de path_year, et si elle existe la récupérer, sinon la créer.\n",
    "        try:\n",
    "            print('Test du try')\n",
    "            df_year = pd.read_excel(path_year, sheet_name = year, engine = 'openpyxl')\n",
    "\n",
    "            print(f\"La page existe ! Tout est bon, on peut continuer\")\n",
    "            df_maj = concat_df_with_multidf_and_drop_dup(df_month, df_year)\n",
    "            #book.remove(year)\n",
    "            df_maj.to_excel(writer, sheet_name = year)\n",
    "\n",
    "            print('Fin du try')\n",
    "\n",
    "        except:\n",
    "            print(f\"La page n'existe pas ! Il faut donc la créer lors de l'ajout de la DataFrame\")\n",
    "            df_maj = concat_df_with_multidf_and_drop_dup(df_month)\n",
    "            df_maj.to_excel(writer, sheet_name = year)\n",
    "\n",
    "            print('Fin du except')\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "\n",
    "    print('Terminé, vous pouvez ouvrir le fichier excel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8765f04-aa24-4ec3-a1c4-edc749bf70b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajout_IF(in_path, out_path, IF_path, year):\n",
    "    \n",
    "    ''' \n",
    "\n",
    "    Args:\n",
    "        in_path (path): path (including name of the file if year != None) leading to the working excel file. \n",
    "        out_path (path): path (including name of the file) leading to where the file will be saved after going through its treatment.\n",
    "        IF_path (path): path (including name of the file) leading to the impact factor excel file.\n",
    "        year (int):\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    Notes:\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    print(f\"in_path = {in_path}\")\n",
    "    \n",
    "    # Standard imports\n",
    "    from pathlib import Path\n",
    "\n",
    "    # Local imports\n",
    "    from BiblioMeter_FUNCTS.BiblioMeterGlobalsVariables import COL_NAMES_BONUS\n",
    "    from BiblioAnalysis_Utils.BiblioSpecificGlobals import COL_NAMES\n",
    "    from BiblioMeter_FUNCTS.BiblioMeterGlobalsVariables import FILL_EMPTY_KEY_WORD\n",
    "\n",
    "    # 3rd party imports\n",
    "    import pandas as pd\n",
    "\n",
    "    # Useful alias\n",
    "    ISSN_alias = COL_NAMES['articles'][10]\n",
    "    EISSN_alias = COL_NAMES_BONUS['EISSN']\n",
    "    IF_alias = COL_NAMES_BONUS['If clarivate']\n",
    "    IF_cours_alias = COL_NAMES_BONUS['IF en cours']\n",
    "    IF_publi_alias = COL_NAMES_BONUS['IF année publi']\n",
    "    \n",
    "    df_submit = pd.read_excel(in_path) # Ma DataFrame\n",
    "    \n",
    "    if year == None:\n",
    "        df_IF = pd.read_excel(IF_path, sheet_name = None)\n",
    "        \n",
    "        # using dictionary to convert type of  Year column\n",
    "        convert_dict = {'Year': str}\n",
    "        df_submit = df_submit.astype(convert_dict)\n",
    "\n",
    "        list_annee = list(df_submit['Year'].unique())\n",
    "        try :\n",
    "            list_annee.remove('unknown')\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "        # Maintenant qu'on a les années, on boucle dessus pour appliquer un filtre\n",
    "        df_submit_bis = pd.DataFrame()\n",
    "        for annee in list_annee:\n",
    "            print(annee)\n",
    "            df_inter = df_submit[df_submit['Year'] == annee]\n",
    "            \n",
    "            try:\n",
    "                dict1 = dict(zip(df_IF[str(int(annee) + 1)][ISSN_alias], df_IF[str(int(annee) + 1)][IF_alias]))\n",
    "                \n",
    "                s = df_inter[ISSN_alias] # Je récup la colonne clef de ma DF en Series\n",
    "                \n",
    "                r = s.map(dict1) # Je map la Series avec mon dictionnaire\n",
    "                                \n",
    "                df_inter[Impact_Factor_alias] = r # Je rajoute la colonne à ma DataFrame\n",
    "                \n",
    "                # Appliquer nan --> unknow to df\n",
    "                df_inter[Impact_Factor_alias] = df_inter[Impact_Factor_alias].fillna(FILL_EMPTY_KEY_WORD)\n",
    "\n",
    "                df_submit_bis = df_submit_bis.append(df_inter)\n",
    "                \n",
    "            except KeyError:\n",
    "                dict1 = dict(zip(df_IF[str(annee)][ISSN_alias], df_IF[str(annee)][IF_alias]))\n",
    "                \n",
    "                s = df_inter[ISSN_alias] # Je récup la colonne clef de ma DF en Series\n",
    "                \n",
    "                r = s.map(dict1) # Je map la Series avec mon dictionnaire\n",
    "                \n",
    "                df_inter[Impact_Factor_alias] = r # Je rajoute la colonne à ma DataFrame\n",
    "                \n",
    "                # Appliquer nan --> unknow to df\n",
    "                df_inter[Impact_Factor_alias] = df_inter[Impact_Factor_alias].fillna(FILL_EMPTY_KEY_WORD)\n",
    "\n",
    "                df_submit_bis = df_submit_bis.append(df_inter)\n",
    "            \n",
    "        df_submit_bis.to_excel(out_path, index = False)\n",
    "                \n",
    "    \n",
    "    else: # Mode de fonctionnement par année\n",
    "        # Check if the year + 1 is available\n",
    "        try:\n",
    "            df_IF = pd.read_excel(IF_path, sheet_name = str(year + 1))\n",
    "            # Ca fonctionne, alors on ajoute la colonne IF de l'année en cours\n",
    "            print(f\"Les IF sortis en {year +1} sont utilisés pour créer la colonne f{IF_cours_alias}\")\n",
    "\n",
    "            dict1 = dict(zip(df_IF[ISSN_alias], df_IF[IF_alias])) # Mon dictionnaire construit à partir de mon fichier excel\n",
    "            s = df_submit[ISSN_alias] # Je récup la colonne clef de ma DF en Series\n",
    "            r = s.map(dict1) # Je map la Series avec mon dictionnaire\n",
    "            df_submit[IF_cours_alias] = r # Je rajoute la colonne à ma DataFrame\n",
    "\n",
    "            # Appliquer nan --> unknow to df TO DO\n",
    "            df_submit[IF_cours_alias] = df_submit[IF_cours_alias].fillna(FILL_EMPTY_KEY_WORD)\n",
    "            \n",
    "            # Et on fait pareil avec les IF de l'année de publication\n",
    "            print(f\"Les IF sortis en {year} sont utilisés pour créer la colonne f{IF_publi_alias}\")\n",
    "\n",
    "            dict1 = dict(zip(df_IF[ISSN_alias], df_IF[IF_alias])) # Mon dictionnaire construit à partir de mon fichier excel\n",
    "            s = df_submit[ISSN_alias] # Je récup la colonne clef de ma DF en Series\n",
    "            r = s.map(dict1) # Je map la Series avec mon dictionnaire\n",
    "            df_submit[IF_publi_alias] = r # Je rajoute la colonne à ma DataFrame\n",
    "\n",
    "            # Appliquer nan --> unknow to df\n",
    "            df_submit[IF_publi_alias] = df_submit[IF_publi_alias].fillna(FILL_EMPTY_KEY_WORD)\n",
    "            \n",
    "            df_submit.to_excel(out_path, index = False)\n",
    "                \n",
    "        except ValueError:\n",
    "            # Check if the year is available, if not, terminate function\n",
    "            try:\n",
    "                df_IF = pd.read_excel(IF_path, sheet_name = str(year))\n",
    "                print(f\"Les IF sortis en {year} sont utilisés\")\n",
    "                \n",
    "                dict1 = dict(zip(df_IF[ISSN_alias], df_IF[IF_alias])) # Mon dictionnaire construit à partir de mon fichier excel\n",
    "                \n",
    "                s = df_submit[ISSN_alias] # Je récup la colonne clef de ma DF en Series\n",
    "                \n",
    "                r = s.map(dict1) # Je map la Series avec mon dictionnaire\n",
    "                \n",
    "                df_submit[Impact_Factor_alias] = r # Je rajoute la colonne à ma DataFrame\n",
    "                \n",
    "                # Appliquer nan --> unknow to df\n",
    "                df_submit[Impact_Factor_alias] = df_submit[Impact_Factor_alias].fillna(FILL_EMPTY_KEY_WORD)\n",
    "\n",
    "                df_submit.to_excel(out_path, index = False)\n",
    "                \n",
    "            except ValueError:\n",
    "                print('Mettre à jour le fichier Impact Factor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a196e872-2c71-4a28-878e-d76793a675ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "in_path = Path(r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\BDD multi annuelle\") / Path(os.listdir(r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\BDD multi annuelle\")[-2])\n",
    "IF_path = Path(r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\Impact Factor\\IF all years.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b7cc0-a176-433b-9f07-bc81d1300fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07e8b7-f0f9-45a8-9fcd-3b223c18297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BiblioMeter_FUNCTS.BiblioMeterFonctions import ajout_IF\n",
    "ajout_IF(in_path, in_path, IF_path, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f58484-7a96-4e94-af6b-be152800f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_IF = pd.read_excel(IF_path, sheet_name = '2023')\n",
    "except ValueError:\n",
    "    try:\n",
    "        df_IF = pd.read_excel(IF_path, sheet_name = '2022')\n",
    "        print('Tout a fonctionné')\n",
    "    except ValueError:\n",
    "        print('Mettre à jour le fichier Impact Factor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c0656b-1ea1-40b9-aeb9-cd08d5ed0744",
   "metadata": {},
   "outputs": [],
   "source": [
    "'2023' in df_IF.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde345f-02b3-47f5-be60-ae042e07774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31d419d-5e3e-4a89-b502-ccc517c76b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9d439f-5148-4a43-a082-2100a1171759",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = Path(r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\BDD multi annuelle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b04496-65d3-4013-8005-501dde8b444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a5ae5a-fd91-48b1-adca-0ec6db303af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_IF.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea649a-8ac1-4a19-b763-76b3eee44e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "IF_path = Path(r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\Impact Factor\\IF all years.xlsx\")\n",
    "\n",
    "df_IF_2021 = pd.read_excel(IF_path, sheet_name = \"2021\")\n",
    "df_IF_2020 = pd.read_excel(IF_path, sheet_name = \"2020\")\n",
    "\n",
    "dict1 = dict(zip(df_IF_2021['Journal Majuscule'], df_IF_2021['ISSN'])) # Création dictionnaire avec les noms des journaux de la fiche 2020 et des ISSN dispo de l’année 2022\n",
    "\n",
    "s = df_IF_2020['Journal Majuscule'] # Mettre en type série la colonne avec les noms des journaux (car le map ne fonctionne qu’avec les séries)\n",
    "\n",
    "r = s.map(dict1) # Effectuer le map avec la série et le dictionnaire\n",
    "\n",
    "df_IF_2020['ISSN'] = r # Rajouter le map (r) à la DF\n",
    "\n",
    "df_IF_2020.to_excel(IF_path, sheet_name = \"2020 new\", header = True) # Envoyer sur le fichier excel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78959713-1f4f-4a44-aafd-0a7703674586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rename_pub_id(old, annee):\n",
    "    return f\"{old}_{annee}\"\n",
    "\n",
    "df['Pub_id'] = df['Pub_id'].apply(lambda x: _rename_pub_id(x, '2014'))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37298395-ca03-41cf-a615-dec36b97f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_column_names(df, dictionnary = None):\n",
    "    '''\n",
    "    The function `rename_column_names` changes names of columns of the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame()):\n",
    "        dictionnary (dict):\n",
    "    \n",
    "    Returns:\n",
    "        df (pandas.DataFrame()):\n",
    "    \n",
    "    Notes:\n",
    "        Uses COL_NAMES_FINALE from BiblioMeter_FUNCTS.BiblioMeterGlobalsVariables\n",
    "    '''\n",
    "    \n",
    "    # 3rd Library imports\n",
    "    import pandas as pd\n",
    "    \n",
    "    if dictionnary == None:\n",
    "        # Local library imports\n",
    "        from BiblioMeter_FUNCTS.BiblioMeterGlobalsVariables import COL_NAMES_FINALE\n",
    "        dictionnary = COL_NAMES_FINALE\n",
    "        \n",
    "    df.rename(columns = dictionnary, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9937b25c-d76f-44c0-a170-f4dd3f1d8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "out_path = r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\2018\\1 - Consolidation Homonymes\\Fichier Consolidation 2018.xlsx\"\n",
    "in_path = r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\2018\\0 - BDD multi mensuelle\\submit.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb3b1d-8552-413f-b132-9f72ba2f96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.read_excel(in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dbe543-d214-43e9-854c-844f9332508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit['Pub_id'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210ef4e-689e-4663-9aa3-62e5eb56a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BiblioMeter_FUNCTS.BiblioMeterFonctions import _liste_de_validation\n",
    "from BiblioMeter_FUNCTS.BiblioMeterFonctions import _you_got_OTPed\n",
    "\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.worksheet.datavalidation import DataValidation\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.utils.cell import get_column_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4506ad65-24bd-4613-9f8f-b7dd5f73b683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mise_en_page(df_submit):\n",
    "        \n",
    "    # 3rd party import\n",
    "    import pandas as pd\n",
    "    from openpyxl import Workbook\n",
    "    from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "    from openpyxl.utils import get_column_letter\n",
    "    from openpyxl.styles import Font, PatternFill, Border, Side, Alignment\n",
    "    from openpyxl.styles.colors import Color\n",
    "    \n",
    "    # Local library import\n",
    "    from BiblioMeter_FUNCTS.BiblioMeterGlobalsVariables import COL_SIZES\n",
    "    \n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = 'Consolidation Homonymes'\n",
    "    \n",
    "    red_ft = PatternFill(fgColor = '00FF0000', fill_type = \"solid\")\n",
    "    blue_ft = PatternFill(fgColor = '0000FFFF', fill_type = \"solid\")\n",
    "    bd = Side(style='medium', color=\"000000\")\n",
    "    active_color = 'red'\n",
    "    \n",
    "    pub_id_unique_list = list(df_submit['Pub_id'].unique())\n",
    "    columns_list = list(df_submit.columns)\n",
    "    \n",
    "    def _le_reste(num, la_list):\n",
    "        return la_list.index(num)%2 == 0\n",
    "        \n",
    "    for indice, r in enumerate(dataframe_to_rows(df_submit, index=False, header=True)):\n",
    "        ws.append(r)        \n",
    "        last_row = ws[ws.max_row]\n",
    "        if indice >= 1:\n",
    "            if _le_reste(df_submit['Pub_id'][indice-1], pub_id_unique_list):\n",
    "                cell = last_row[0]\n",
    "                cell.fill = red_ft\n",
    "                if active_color != 'red':\n",
    "                    for cell_bis in last_row:\n",
    "                        cell_bis.border = Border(top=bd)\n",
    "                        active_color = 'red'\n",
    "            else:\n",
    "                cell = last_row[0]\n",
    "                cell.fill = blue_ft\n",
    "                if active_color != 'blue':\n",
    "                    for cell_bis in last_row:\n",
    "                        cell_bis.border = Border(top=bd)\n",
    "                        active_color = 'blue'\n",
    "\n",
    "    for cell in ws['A'] + ws[1]:\n",
    "        cell.font = Font(bold=True)\n",
    "        cell.border = Border(left=bd, top=bd, right=bd, bottom=bd)\n",
    "        cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "        \n",
    "    for i, col in enumerate(columns_list):\n",
    "        if i >= 1:\n",
    "            try:\n",
    "                ws.column_dimensions[get_column_letter(i+1)].width = COL_SIZES[col]\n",
    "            except:\n",
    "                ws.column_dimensions[get_column_letter(i+1)].width = 15\n",
    "        \n",
    "    ws.row_dimensions[1].height = 30\n",
    "    \n",
    "    wb.save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e7513ec-ebf2-4edb-9070-edad7420f972",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_displays' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_46144\\60657547.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Get screens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mDisplays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_displays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdisplays_nb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDisplays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_displays' is not defined"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import Tk\n",
    "from tkinter import ttk\n",
    "from screeninfo import get_monitors\n",
    "get_monitors()\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "# Get screens\n",
    "Displays = get_displays()\n",
    "\n",
    "displays_nb = len(Displays)\n",
    "GUI_DISP = [i for i in range(displays_nb) if Displays[i]['is_primary']][0]\n",
    "ppi = Displays[GUI_DISP][\"ppi\"]\n",
    "\n",
    "root, scale_factor, win_width, win_height = general_properties(root)\n",
    "\n",
    "print(win_width, win_height)\n",
    "\n",
    "# Set the fontsize based on scale_factor,\n",
    "# if the fontsize is less than minimum_size\n",
    "# it is set to the minimum size\n",
    "def _font_size(size, scale_factor):\n",
    "    \n",
    "    fontsize = int(size * scale_factor)\n",
    "    \n",
    "    minimum_size = 8\n",
    "    if fontsize < minimum_size:\n",
    "        fontsize = minimum_size\n",
    "        \n",
    "    return fontsize\n",
    "\n",
    "### Choose which year you want to be working with #############################################################################################################\n",
    "years_list = [2021, 2022]\n",
    "years_var = tk.StringVar(root)\n",
    "years_var.set(years_list[0])\n",
    "    \n",
    "# Création de l'option button des années\n",
    "OptionButton_years = tk.OptionMenu(root, years_var, *years_list)\n",
    "\n",
    "button1 = tk.Button(root, text=\"Section 1\", font = (\"Helvetica\", _font_size(35, scale_factor)))\n",
    "button1.place(x = win_width/2, y = win_height/4*1, anchor = 'center')\n",
    "\n",
    "button2 = tk.Button(root, text=\"Section 2\", font = (\"Helvetica\", _font_size(15, scale_factor)))\n",
    "button2.place(x = win_width/2, y = win_height/4*3, anchor = 'center')\n",
    "\n",
    "entry1 = tk.Entry(root, width = 41)\n",
    "entry1.place(x = win_width/2, y =  win_height/4*2, anchor = 'center')\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f12d1f84-8455-4b5b-8f6e-1ad40c818e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_properties(self):\n",
    "\n",
    "    # Base size\n",
    "    normal_width = 1920\n",
    "    normal_height = 1080\n",
    "\n",
    "    # Get screen size\n",
    "    screen_width = self.winfo_screenwidth()\n",
    "    print(screen_width)\n",
    "    screen_height = self.winfo_screenheight()\n",
    "    print(screen_height)\n",
    "\n",
    "    # Get percentage of screen size from Base size\n",
    "    percentage_width = screen_width / (normal_width / 100)\n",
    "    percentage_height = screen_height / (normal_height / 100)\n",
    "\n",
    "    # Make a scaling factor, this is bases on average percentage from\n",
    "    # width and height.\n",
    "    scale_factor = ((percentage_width + percentage_height) / 2) / 100\n",
    "    \n",
    "    # Set window size depending on scale factor\n",
    "    win_width = int(screen_width*0.47*scale_factor)\n",
    "    win_height = int(screen_height*0.65*scale_factor)\n",
    "\n",
    "    # Set window size depending on scalre factor\n",
    "    self.geometry(f\"{win_width}x{win_height}\")\n",
    "    self.resizable(False, False)\n",
    "    \n",
    "    # Set title window\n",
    "    self.title('BiblioMeter')\n",
    "    \n",
    "    return self, scale_factor, win_width, win_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95679e44-9b6f-4f96-8621-e0adf8dfcf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "173 mm = 699 px largeur\n",
    "233 mm = 901 px hauteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae153e0-dbeb-4673-84be-c2a0e660d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mm_to_px(size_mm, ppi ,fact = 1.0):\n",
    "    '''The `_mm_to_px' function converts a value in mm to a value in pixels\n",
    "    using the ppi of the used display and a factor fact.\n",
    "    \n",
    "    Args:\n",
    "        size_mm (float): value in mm to be converted.\n",
    "        ppi ( float): pixels per inch of the display.\n",
    "        fact (float): factor (default= 1).\n",
    "        \n",
    "    Returns:\n",
    "        `(int)`: upper integer value of the conversion to pixels\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # Standard library imports \n",
    "    import math\n",
    "    \n",
    "    # Local imports\n",
    "    from BiblioAnalysis_Utils.BiblioGeneralGlobals import IN_TO_MM\n",
    "\n",
    "    size_px = math.ceil((size_mm * fact / IN_TO_MM) * ppi)\n",
    "    \n",
    "    return size_px\n",
    "\n",
    "def get_displays(in_to_mm = None): \n",
    "    \n",
    "    ''' The function `get_displays` allows to identify the set of displays\n",
    "        available within the user hardware and to get their parameters.\n",
    "        If the width or the height of a display are not available in mm \n",
    "        through the `get_monitors` method (as for Darwin platforms), \n",
    "        the user is asked to specify the displays diagonal size to compute them.\n",
    "        \n",
    "    Returns:\n",
    "        `list`: list of dicts with one dict per detected display,\n",
    "                each dict is keyed by 8 display parameters.   \n",
    "    '''\n",
    "    # To Do: convert prints and inputs to gui displays and inputs\n",
    "    \n",
    "    # Standard library imports\n",
    "    import math\n",
    "    \n",
    "    # 3rd party imports\n",
    "    from screeninfo import get_monitors\n",
    "    \n",
    "    # Local imports\n",
    "    from BiblioAnalysis_Utils.BiblioGeneralGlobals import IN_TO_MM\n",
    "\n",
    "    if in_to_mm==None: in_to_mm = IN_TO_MM\n",
    "    \n",
    "    displays = [{'x':m.x,'y':m.y,'width':m.width,\n",
    "                 'height':m.height,'width_mm':m.width_mm,\n",
    "                 'height_mm':m.height_mm,'name':m.name,\n",
    "                 'is_primary':m.is_primary} for m in get_monitors()]\n",
    "    \n",
    "\n",
    "    print('Number of detected displays:',len(displays))\n",
    "    \n",
    "    for disp in range(len(displays)):\n",
    "        width_px = displays[disp]['width']\n",
    "        height_px = displays[disp]['height']\n",
    "        diag_px = math.sqrt(int(width_px)**2 + int(height_px)**2)    \n",
    "        width_mm = displays[disp]['width_mm']\n",
    "        height_mm = displays[disp]['height_mm']\n",
    "        if width_mm is None or height_mm is None: \n",
    "            diag_in = float(input('Enter the diagonal size of the screen n°' + str(disp) + ' (inches)'))\n",
    "            width_mm = round(int(width_px) * (diag_in/diag_px) * in_to_mm,1)\n",
    "            height_mm = round(int(height_px) * (diag_in/diag_px) * in_to_mm,1)\n",
    "            displays[disp]['width_mm'] = str(width_mm)\n",
    "            displays[disp]['height_mm'] = str(height_mm)\n",
    "        else:\n",
    "            diag_in = math.sqrt(float(width_mm) ** 2 + float(height_mm) ** 2) / in_to_mm\n",
    "        displays[disp]['ppi'] = round(diag_px/diag_in,2)\n",
    "        \n",
    "    return displays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d3dc71-a0b0-409c-99c4-dee90d24ccc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Monitor(x=-1680, y=-15, width=1680, height=1050, width_mm=473, height_mm=296, name='\\\\\\\\.\\\\DISPLAY2', is_primary=False),\n",
       " Monitor(x=0, y=0, width=1920, height=1080, width_mm=476, height_mm=267, name='\\\\\\\\.\\\\DISPLAY3', is_primary=True),\n",
       " Monitor(x=-3600, y=188, width=1920, height=1080, width_mm=309, height_mm=174, name='\\\\\\\\.\\\\DISPLAY1', is_primary=False)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from screeninfo import get_monitors\n",
    "get_monitors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c9497-6758-4188-b642-1877e7b22447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BiblioMeter_kernel",
   "language": "python",
   "name": "bibliometer_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
