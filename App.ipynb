{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9921e8-3662-4790-a7a0-d7ee20215366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\LD259969\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LD259969\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LD259969\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from BiblioMeter_GUI.Page_Classes import App_Test\n",
    "\n",
    "app = App_Test()\n",
    "app.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2879ada2-703f-413e-8aa8-92a668cc132c",
   "metadata": {},
   "source": [
    "# Début du brouillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9469ef0a-689c-412d-a208-9f96f3f8dcd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AJOUTER AUTOMATIQUEMENT CETTE FONCTION A LA PROCEDURE DONE\n",
    "\n",
    "import pandas as pd\n",
    "from BiblioMeter_FUNCTS.BiblioMeterFonctions import add_authors_name_list\n",
    "\n",
    "in_path = r'S:/130-LITEN/130.1-Direction/130.1.2-Direction Scientifique/130.1.2.1-Dossiers en cours/111- Ludovic Desmeuzes/BiblioMeter_Files/2022/BDD multi mensuelle/submit.xlsx'\n",
    "out_path = r'S:/130-LITEN/130.1-Direction/130.1.2-Direction Scientifique/130.1.2.1-Dossiers en cours/111- Ludovic Desmeuzes/BiblioMeter_Files/2022/BDD multi mensuelle/submit.xlsx'\n",
    "\n",
    "add_authors_name_list(in_path, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c4599-fd2b-41c5-8469-dc96de3b6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "in_path = r'S:/130-LITEN/130.1-Direction/130.1.2-Direction Scientifique/130.1.2.1-Dossiers en cours/111- Ludovic Desmeuzes/BiblioMeter_Files/2022/BDD multi mensuelle/submit.xlsx'\n",
    "out_path = r'S:/130-LITEN/130.1-Direction/130.1.2-Direction Scientifique/130.1.2.1-Dossiers en cours/111- Ludovic Desmeuzes/BiblioMeter_Files/2022/BDD multi mensuelle/cleaned_submit.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba2b1b8-5cd8-4b4d-8840-43c7a800afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BiblioMeter_FUNCTS import clean_reorder_rename_submit\n",
    "clean_reorder_rename_submit(in_path, out_path)\n",
    "# A FINIR APRES IMPACT FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b109ab-e304-4b08-8693-62d305beac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes pour écrire dans un document texte\n",
    "path = r'S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\111- Ludovic Desmeuzes\\BiblioMeter_Files\\Listing RH\\MAJ.txt'\n",
    "f = open(path,'r')\n",
    "print(f.readline())\n",
    "f.close()\n",
    "\n",
    "f = open(path,'w')\n",
    "nouvelle_date = f'{date.today().month}/{date.today().year}'\n",
    "f.writelines(nouvelle_date)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04d4b92-2837-4d4d-8946-fd6a01d14039",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def maj_listing_RH():\n",
    "\n",
    "    def date_compare(list_of_dates, comparator):\n",
    "        '''\n",
    "        Args:\n",
    "            list_of_dates (list of strings): a list of string of dates in format mmyyyy, mm being the number of the month and yyyy being the number of the year.\n",
    "            comparator (string): a date in string format mmyyyy, mm being the number of the month and yyyy being the number of the year.\n",
    "\n",
    "        Returns:\n",
    "            L (list of strings): a list of the dates older than the comparator date.\n",
    "\n",
    "        '''\n",
    "        L = []\n",
    "        for i in list_of_dates:\n",
    "            if i[2:6] > comparator[2:6]:\n",
    "                # Alors ok pas besoin de vérifier\n",
    "                L.append(i)\n",
    "            elif i[2:6] == comparator[2:6]:\n",
    "                if i[0:2] > comparator[0:2]:\n",
    "                    # Okay si le mois est supérieur\n",
    "                    L.append(i)\n",
    "        return L\n",
    "\n",
    "    def concat_df_with_multidf_and_drop_dup(multi_df, df = pd.DataFrame()):\n",
    "        '''\n",
    "        Args:\n",
    "            multi_df (DataFrame):\n",
    "            df (DataFrame):\n",
    "        Returns:\n",
    "            df (DataFrame):\n",
    "        '''\n",
    "        for i in range(len(multi_df)):\n",
    "            clef = list(df_month.keys())[i]\n",
    "            df = df.append(multi_df[clef])\n",
    "        df.drop_duplicates(subset=['Matricule'], keep='first', inplace=True, ignore_index=False)\n",
    "        return df\n",
    "\n",
    "    def different_years(list_of_dates):\n",
    "        '''\n",
    "        Args:\n",
    "            list_of_dates (list of strings): a list of string of dates in format mmyyyy, mm being the number of the month and yyyy being the number of the year.\n",
    "        Returns:\n",
    "            L (list of strings):\n",
    "        '''\n",
    "        L = []\n",
    "        for i in list_of_dates:\n",
    "            L.append(i[2:6])\n",
    "        return list(set(L))\n",
    "\n",
    "    def dates_of_the_given_year(given_year, list_of_dates):\n",
    "        '''\n",
    "        Args:\n",
    "            given_year (string):\n",
    "            list_of_dates (list of strings): a list of string of dates in format mmyyyy, mm being the number of the month and yyyy being the number of the year.\n",
    "        Returns:\n",
    "            L (list of strings):\n",
    "        '''\n",
    "        L = []\n",
    "        for i in list_of_dates:\n",
    "            if i[2:6] == given_year:\n",
    "                L.append(i)\n",
    "        return L\n",
    "\n",
    "    # Mise à jour fichier RH\n",
    "\n",
    "    import pandas as pd \n",
    "    import numpy as np \n",
    "    from openpyxl import load_workbook \n",
    "\n",
    "    path_year = r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\111- Ludovic Desmeuzes\\BiblioMeter_Files\\Listing RH\\All_effectifs.xlsx\" \n",
    "    path_month = r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\111- Ludovic Desmeuzes\\BiblioMeter_Files\\Listing RH\\Effectifs_2010_2022.xlsx\" \n",
    "    path_maj = r'S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\111- Ludovic Desmeuzes\\BiblioMeter_Files\\Listing RH\\MAJ.txt'\n",
    "\n",
    "    # Récupérer la date de la dernière MAJ\n",
    "    f = open(path_maj,'r')\n",
    "    last_maj = f.readline()\n",
    "    f.close()\n",
    "\n",
    "    # Récupérer les pages dont les dates sont antérieures à last_maj\n",
    "    xls = pd.ExcelFile(path_month, engine = 'openpyxl')\n",
    "    sheets = xls.sheet_names\n",
    "    excel_sheets = date_compare(sheets, last_maj)\n",
    "    print(f\"Toutes les pages à maj sont {excel_sheets}\")\n",
    "\n",
    "    # Récupérer les différentes années et boucler dessus\n",
    "    diff_years = different_years(excel_sheets)\n",
    "    print(f\"Les années différentes sur ces pages sont {diff_years}\")\n",
    "\n",
    "    # Ouverture du workbook et writer\n",
    "    book = load_workbook(path_year)\n",
    "    writer = pd.ExcelWriter(path_year, engine = 'openpyxl', mode = 'a', if_sheet_exists = 'replace') \n",
    "    # writer.book = book\n",
    "\n",
    "    for year in diff_years:\n",
    "        # Les dates des pages à rajouter pour l'année en question\n",
    "        month_pages = dates_of_the_given_year(year, excel_sheets)\n",
    "        print(f\"Pour l'année {year}, les mois sont {month_pages}\")\n",
    "\n",
    "        # La multi df à récupérer de l'année en question pour mettre à jour le fichier effectif de l'année\n",
    "        df_month = pd.read_excel(path_month, sheet_name = month_pages)\n",
    "\n",
    "        # Vérifier l'excistence de la page de l'année de path_year, et si elle existe la récupérer, sinon la créer.\n",
    "        try:\n",
    "            print('Test du try')\n",
    "            df_year = pd.read_excel(path_year, sheet_name = year, engine = 'openpyxl')\n",
    "\n",
    "            print(f\"La page existe ! Tout est bon, on peut continuer\")\n",
    "            df_maj = concat_df_with_multidf_and_drop_dup(df_month, df_year)\n",
    "            #book.remove(year)\n",
    "            df_maj.to_excel(writer, sheet_name = year)\n",
    "\n",
    "            print('Fin du try')\n",
    "\n",
    "        except:\n",
    "            print(f\"La page n'existe pas ! Il faut donc la créer lors de l'ajout de la DataFrame\")\n",
    "            df_maj = concat_df_with_multidf_and_drop_dup(df_month)\n",
    "            df_maj.to_excel(writer, sheet_name = year)\n",
    "\n",
    "            print('Fin du except')\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "\n",
    "    print('Terminé, vous pouvez ouvrir le fichier excel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8765f04-aa24-4ec3-a1c4-edc749bf70b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajout_IF(in_path, out_path, IF_path, year):\n",
    "    \n",
    "    ''' \n",
    "\n",
    "    Args:\n",
    "        in_path (path): path (including name of the file if year != None) leading to the working excel file. \n",
    "        out_path (path): path (including name of the file) leading to where the file will be saved after going through its treatment.\n",
    "        IF_path (path): path (including name of the file) leading to the impact factor excel file.\n",
    "        year (int):\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    Notes:\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    print(f\"in_path = {in_path}\")\n",
    "    \n",
    "    # Standard imports\n",
    "    from pathlib import Path\n",
    "\n",
    "    # Local imports\n",
    "    from BiblioMeter_FUNCTS.BiblioMeterGlobalsVariables import COL_NAMES_BONUS\n",
    "    from BiblioAnalysis_Utils.BiblioSpecificGlobals import COL_NAMES\n",
    "    from BiblioMeter_FUNCTS.BiblioMeterGlobalsVariables import FILL_EMPTY_KEY_WORD\n",
    "\n",
    "    # 3rd party imports\n",
    "    import pandas as pd\n",
    "\n",
    "    # Useful alias\n",
    "    ISSN_alias = COL_NAMES['articles'][10]\n",
    "    EISSN_alias = COL_NAMES_BONUS['EISSN']\n",
    "    IF_alias = COL_NAMES_BONUS['If clarivate']\n",
    "    IF_cours_alias = COL_NAMES_BONUS['IF en cours']\n",
    "    IF_publi_alias = COL_NAMES_BONUS['IF année publi']\n",
    "    \n",
    "    df_submit = pd.read_excel(in_path) # Ma DataFrame\n",
    "    \n",
    "    if year == None:\n",
    "        df_IF = pd.read_excel(IF_path, sheet_name = None)\n",
    "        \n",
    "        # using dictionary to convert type of  Year column\n",
    "        convert_dict = {'Year': str}\n",
    "        df_submit = df_submit.astype(convert_dict)\n",
    "\n",
    "        list_annee = list(df_submit['Year'].unique())\n",
    "        try :\n",
    "            list_annee.remove('unknown')\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "        # Maintenant qu'on a les années, on boucle dessus pour appliquer un filtre\n",
    "        df_submit_bis = pd.DataFrame()\n",
    "        for annee in list_annee:\n",
    "            print(annee)\n",
    "            df_inter = df_submit[df_submit['Year'] == annee]\n",
    "            \n",
    "            try:\n",
    "                dict1 = dict(zip(df_IF[str(int(annee) + 1)][ISSN_alias], df_IF[str(int(annee) + 1)][IF_alias]))\n",
    "                \n",
    "                s = df_inter[ISSN_alias] # Je récup la colonne clef de ma DF en Series\n",
    "                \n",
    "                r = s.map(dict1) # Je map la Series avec mon dictionnaire\n",
    "                                \n",
    "                df_inter[Impact_Factor_alias] = r # Je rajoute la colonne à ma DataFrame\n",
    "                \n",
    "                # Appliquer nan --> unknow to df\n",
    "                df_inter[Impact_Factor_alias] = df_inter[Impact_Factor_alias].fillna(FILL_EMPTY_KEY_WORD)\n",
    "\n",
    "                df_submit_bis = df_submit_bis.append(df_inter)\n",
    "                \n",
    "            except KeyError:\n",
    "                dict1 = dict(zip(df_IF[str(annee)][ISSN_alias], df_IF[str(annee)][IF_alias]))\n",
    "                \n",
    "                s = df_inter[ISSN_alias] # Je récup la colonne clef de ma DF en Series\n",
    "                \n",
    "                r = s.map(dict1) # Je map la Series avec mon dictionnaire\n",
    "                \n",
    "                df_inter[Impact_Factor_alias] = r # Je rajoute la colonne à ma DataFrame\n",
    "                \n",
    "                # Appliquer nan --> unknow to df\n",
    "                df_inter[Impact_Factor_alias] = df_inter[Impact_Factor_alias].fillna(FILL_EMPTY_KEY_WORD)\n",
    "\n",
    "                df_submit_bis = df_submit_bis.append(df_inter)\n",
    "            \n",
    "        df_submit_bis.to_excel(out_path, index = False)\n",
    "                \n",
    "    \n",
    "    else: # Mode de fonctionnement par année\n",
    "        # Check if the year + 1 is available\n",
    "        try:\n",
    "            df_IF = pd.read_excel(IF_path, sheet_name = str(year + 1))\n",
    "            # Ca fonctionne, alors on ajoute la colonne IF de l'année en cours\n",
    "            print(f\"Les IF sortis en {year +1} sont utilisés pour créer la colonne f{IF_cours_alias}\")\n",
    "\n",
    "            dict1 = dict(zip(df_IF[ISSN_alias], df_IF[IF_alias])) # Mon dictionnaire construit à partir de mon fichier excel\n",
    "            s = df_submit[ISSN_alias] # Je récup la colonne clef de ma DF en Series\n",
    "            r = s.map(dict1) # Je map la Series avec mon dictionnaire\n",
    "            df_submit[IF_cours_alias] = r # Je rajoute la colonne à ma DataFrame\n",
    "\n",
    "            # Appliquer nan --> unknow to df TO DO\n",
    "            df_submit[IF_cours_alias] = df_submit[IF_cours_alias].fillna(FILL_EMPTY_KEY_WORD)\n",
    "            \n",
    "            # Et on fait pareil avec les IF de l'année de publication\n",
    "            print(f\"Les IF sortis en {year} sont utilisés pour créer la colonne f{IF_publi_alias}\")\n",
    "\n",
    "            dict1 = dict(zip(df_IF[ISSN_alias], df_IF[IF_alias])) # Mon dictionnaire construit à partir de mon fichier excel\n",
    "            s = df_submit[ISSN_alias] # Je récup la colonne clef de ma DF en Series\n",
    "            r = s.map(dict1) # Je map la Series avec mon dictionnaire\n",
    "            df_submit[IF_publi_alias] = r # Je rajoute la colonne à ma DataFrame\n",
    "\n",
    "            # Appliquer nan --> unknow to df\n",
    "            df_submit[IF_publi_alias] = df_submit[IF_publi_alias].fillna(FILL_EMPTY_KEY_WORD)\n",
    "            \n",
    "            df_submit.to_excel(out_path, index = False)\n",
    "                \n",
    "        except ValueError:\n",
    "            # Check if the year is available, if not, terminate function\n",
    "            try:\n",
    "                df_IF = pd.read_excel(IF_path, sheet_name = str(year))\n",
    "                print(f\"Les IF sortis en {year} sont utilisés\")\n",
    "                \n",
    "                dict1 = dict(zip(df_IF[ISSN_alias], df_IF[IF_alias])) # Mon dictionnaire construit à partir de mon fichier excel\n",
    "                \n",
    "                s = df_submit[ISSN_alias] # Je récup la colonne clef de ma DF en Series\n",
    "                \n",
    "                r = s.map(dict1) # Je map la Series avec mon dictionnaire\n",
    "                \n",
    "                df_submit[Impact_Factor_alias] = r # Je rajoute la colonne à ma DataFrame\n",
    "                \n",
    "                # Appliquer nan --> unknow to df\n",
    "                df_submit[Impact_Factor_alias] = df_submit[Impact_Factor_alias].fillna(FILL_EMPTY_KEY_WORD)\n",
    "\n",
    "                df_submit.to_excel(out_path, index = False)\n",
    "                \n",
    "            except ValueError:\n",
    "                print('Mettre à jour le fichier Impact Factor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a196e872-2c71-4a28-878e-d76793a675ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "in_path = Path(r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\BDD multi annuelle\") / Path(os.listdir(r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\BDD multi annuelle\")[-2])\n",
    "IF_path = Path(r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\Impact Factor\\IF all years.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b7cc0-a176-433b-9f07-bc81d1300fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07e8b7-f0f9-45a8-9fcd-3b223c18297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BiblioMeter_FUNCTS.BiblioMeterFonctions import ajout_IF\n",
    "ajout_IF(in_path, in_path, IF_path, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f58484-7a96-4e94-af6b-be152800f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_IF = pd.read_excel(IF_path, sheet_name = '2023')\n",
    "except ValueError:\n",
    "    try:\n",
    "        df_IF = pd.read_excel(IF_path, sheet_name = '2022')\n",
    "        print('Tout a fonctionné')\n",
    "    except ValueError:\n",
    "        print('Mettre à jour le fichier Impact Factor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c0656b-1ea1-40b9-aeb9-cd08d5ed0744",
   "metadata": {},
   "outputs": [],
   "source": [
    "'2023' in df_IF.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde345f-02b3-47f5-be60-ae042e07774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_IF = pd.read_excel(IF_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31d419d-5e3e-4a89-b502-ccc517c76b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9d439f-5148-4a43-a082-2100a1171759",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = Path(r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\BDD multi annuelle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b04496-65d3-4013-8005-501dde8b444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a5ae5a-fd91-48b1-adca-0ec6db303af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_IF.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea649a-8ac1-4a19-b763-76b3eee44e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "IF_path = Path(r\"S:\\130-LITEN\\130.1-Direction\\130.1.2-Direction Scientifique\\130.1.2.1-Dossiers en cours\\110-Alternants\\2021-22 Ludovic Desmeuzes\\BiblioMeter_Files\\Impact Factor\\IF all years.xlsx\")\n",
    "\n",
    "df_IF_2021 = pd.read_excel(IF_path, sheet_name = \"2021\")\n",
    "df_IF_2020 = pd.read_excel(IF_path, sheet_name = \"2020\")\n",
    "\n",
    "dict1 = dict(zip(df_IF_2021['Journal Majuscule'], df_IF_2021['ISSN'])) # Création dictionnaire avec les noms des journaux de la fiche 2020 et des ISSN dispo de l’année 2022\n",
    "\n",
    "s = df_IF_2020['Journal Majuscule'] # Mettre en type série la colonne avec les noms des journaux (car le map ne fonctionne qu’avec les séries)\n",
    "\n",
    "r = s.map(dict1) # Effectuer le map avec la série et le dictionnaire\n",
    "\n",
    "df_IF_2020['ISSN'] = r # Rajouter le map (r) à la DF\n",
    "\n",
    "df_IF_2020.to_excel(IF_path, sheet_name = \"2020 new\", header = True) # Envoyer sur le fichier excel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e5a5c2-ef56-428c-984e-954f5c91202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_IF['JCR Abbreviated Title'][1299])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708ad721-0245-457c-a4eb-a23eff1aea25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f4587-24a6-4c3b-a325-d94b35dcff62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab43b79-3dfc-4cdd-bfc2-adc15d88545a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0ff8f5-a5da-4d18-a27e-b1548bd0483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'salut cOmmEnt ça Va ?'\n",
    "b = a.title()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d7c5ff-c449-4beb-b96f-eb3cd8275bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "737d008b-c66a-4d9f-9a18-a6d76ddce84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "def _place_after(w,cible,dx=5,dy=0):\n",
    "    cible_info = cible.place_info()\n",
    "    x = dx + int(cible_info['x']) + cible.winfo_reqwidth()\n",
    "    y = int(cible_info['y']) + cible.winfo_reqheight()/2 + dy\n",
    "    w.place(x = x, y = y, anchor = 'w')\n",
    "    \n",
    "def _encadre_label_button(fond, label, button, dx = 10, dy = 10):\n",
    "    \n",
    "    fond.delete('all')\n",
    "    label_info = label.place_info()\n",
    "    button_info = button.place_info()\n",
    "\n",
    "    x1 = int(button_info['x']) - dx\n",
    "    y1 = int(button_info['y']) - dy\n",
    "    x2 = int(button_info['x']) + button.winfo_reqwidth() + label.winfo_reqwidth() + dx\n",
    "    y2 = int(label_info['y']) + max(button.winfo_reqheight()/2, label.winfo_reqheight()) + dx\n",
    "\n",
    "    rectangle = fond.create_rectangle(x1, y1, x2, y2, outline = \"red\", width = 2)\n",
    "    fond.place(x = 0, y = 0)\n",
    "\n",
    "class App:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        x_root = 500\n",
    "        y_root = 500\n",
    "        self.root.geometry(f\"{x_root}x{y_root}\")\n",
    "        self.fond = tk.Canvas(self.root, width =  x_root, height =  y_root)\n",
    "        \n",
    "        \n",
    "        # Vous pouvez vous amuser à déplacer le bouton, et à jouer sur sa taille (limite 500 x 500)\n",
    "        self.b = tk.Button(self.root, height = 3)\n",
    "        self.b.place(x=220, y=85)\n",
    "        \n",
    "        self.l = tk.Label(self.root, text='ya plus dsauc\\'')\n",
    "        tk.Scale(self.root, from_=0, to=20, command=self.actu,\n",
    "                 orient='horizontal').place(x=17,y=79)\n",
    "        \n",
    "        self.root.mainloop()\n",
    "        \n",
    "    def actu(self, arg):\n",
    "        self.b['text'] = 'gretchipdertubachagtirengo'[:int(arg)]\n",
    "        self.b['width'] = len('gretchipdertubachagtirengo'[:int(arg)])\n",
    "        _place_after(self.l, self.b, dy=2)\n",
    "        _encadre_label_button(self.fond, self.l, self.b)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    App()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78959713-1f4f-4a44-aafd-0a7703674586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BiblioMeter_kernel",
   "language": "python",
   "name": "bibliometer_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
